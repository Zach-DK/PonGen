{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39496b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displayed frame: 09-08-2025_00-43-24_3167.png\n",
      "Image size: (200, 200)\n",
      "Tensor shape: (200, 200)\n",
      "Tensor dtype: float32\n",
      "Min value: 0.0, Max value: 255.0\n",
      "\n",
      "Black channel tensor (200x200):\n",
      "[[  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " [  0.   0.   0. ...   0.   0.   0.]\n",
      " ...\n",
      " [ 38.  42.   0. ...   0. 113. 105.]\n",
      " [ 21.  49.  42. ...  55. 164. 123.]\n",
      " [ 21.  21.  38. ...  38. 149. 185.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the frames directory\n",
    "frames_dir = \"frames\"\n",
    "\n",
    "# Check if frames directory exists\n",
    "if not os.path.exists(frames_dir):\n",
    "    print(f\"Frames directory '{frames_dir}' not found!\")\n",
    "else:\n",
    "    # Get all PNG files in the frames directory\n",
    "    frame_files = [f for f in os.listdir(frames_dir) if f.endswith('.png')]\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(\"No PNG files found in frames directory!\")\n",
    "    else:\n",
    "        # Select a random frame\n",
    "        random_frame = random.choice(frame_files)\n",
    "        frame_path = os.path.join(frames_dir, random_frame)\n",
    "        \n",
    "        # Load and display the image\n",
    "        img = Image.open(frame_path)\n",
    "        \n",
    "        print(f\"Displayed frame: {random_frame}\")\n",
    "        print(f\"Image size: {img.size}\")\n",
    "\n",
    "        \n",
    "        # Convert image to tensor and extract black channel\n",
    "        import numpy as np\n",
    "        \n",
    "        # Convert PIL image to numpy array\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Check if image is RGB or RGBA\n",
    "        if len(img_array.shape) == 3:\n",
    "            black_channel = img_array[:, :, 0]\n",
    "        else:\n",
    "            # If it's already grayscale\n",
    "            black_channel = img_array\n",
    "        \n",
    "        # Convert to tensor (numpy array) and ensure it's 200x200\n",
    "        tensor_200x200 = black_channel.astype(np.float32)\n",
    "        \n",
    "        print(f\"Tensor shape: {tensor_200x200.shape}\")\n",
    "        print(f\"Tensor dtype: {tensor_200x200.dtype}\")\n",
    "        print(f\"Min value: {tensor_200x200.min()}, Max value: {tensor_200x200.max()}\")\n",
    "        print(\"\\nBlack channel tensor (200x200):\")\n",
    "        print(tensor_200x200)\n",
    "\n",
    "        # Display both images as subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title(f\"Random Frame: {random_frame}\")\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(tensor_200x200, cmap='gray', vmin=0, vmax=255)\n",
    "        ax2.set_title(\"Tensor 200x200 (Black Channel)\")\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fc82cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created successfully!\n",
      "Total parameters: 1,949,409\n",
      "Trainable parameters: 1,949,409\n",
      "Model size: ~7.4 MB (FP32)\n",
      "Using GPU: NVIDIA GeForce RTX 4070 SUPER\n",
      "\n",
      "Inference Performance:\n",
      "Average inference time: 1.57 ms\n",
      "Theoretical max FPS: 637.5\n",
      "Real-time capable (60fps): ✓ YES\n",
      "Output shape: torch.Size([1, 1, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RealTimePongPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight U-Net for real-time next-frame prediction in Pong\n",
    "    Optimized for <16ms inference time on GPU for 60fps gameplay\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RealTimePongPredictor, self).__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.enc1 = self._conv_block(2, 32)       # Input: 2 frames (t-1, t)\n",
    "        self.enc2 = self._conv_block(32, 64)      # 100x100 -> 100x100  \n",
    "        self.enc3 = self._conv_block(64, 128)     # 50x50 -> 50x50\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._conv_block(128, 256)  # 25x25 -> 25x25\n",
    "        \n",
    "        # Decoder (upsampling) with skip connections\n",
    "        self.dec3 = self._conv_block(256 + 128, 128)  # +128 from skip connection\n",
    "        self.dec2 = self._conv_block(128 + 64, 64)    # +64 from skip connection  \n",
    "        self.dec1 = self._conv_block(64 + 32, 32)     # +32 from skip connection\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Lightweight convolution block\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Concatenated input frames [batch_size, 2, 200, 200] where x[:,0]=t-1, x[:,1]=t\n",
    "        Returns:\n",
    "            next_frame: Predicted next frame [batch_size, 1, 200, 200]\n",
    "        \"\"\"\n",
    "        # Encoder with skip connections\n",
    "        e1 = self.enc1(x)           # [B, 32, 200, 200]\n",
    "        e1_pool = F.max_pool2d(e1, 2)  # [B, 32, 100, 100]\n",
    "        \n",
    "        e2 = self.enc2(e1_pool)     # [B, 64, 100, 100]\n",
    "        e2_pool = F.max_pool2d(e2, 2)  # [B, 64, 50, 50]\n",
    "        \n",
    "        e3 = self.enc3(e2_pool)     # [B, 128, 50, 50]\n",
    "        e3_pool = F.max_pool2d(e3, 2)  # [B, 128, 25, 25]\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(e3_pool)  # [B, 256, 25, 25]\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d3 = F.interpolate(bottleneck, size=(50, 50), mode='bilinear', align_corners=False)\n",
    "        d3 = torch.cat([d3, e3], dim=1)  # Skip connection\n",
    "        d3 = self.dec3(d3)  # [B, 128, 50, 50]\n",
    "        \n",
    "        d2 = F.interpolate(d3, size=(100, 100), mode='bilinear', align_corners=False)\n",
    "        d2 = torch.cat([d2, e2], dim=1)  # Skip connection\n",
    "        d2 = self.dec2(d2)  # [B, 64, 100, 100]\n",
    "        \n",
    "        d1 = F.interpolate(d2, size=(200, 200), mode='bilinear', align_corners=False)\n",
    "        d1 = torch.cat([d1, e1], dim=1)  # Skip connection\n",
    "        d1 = self.dec1(d1)  # [B, 32, 200, 200]\n",
    "        \n",
    "        # Predict residual delta in [-1,1], then add to latest frame\n",
    "        residual = torch.tanh(self.final(d1))  # [B, 1, 200, 200]\n",
    "        latest = x[:, 1:2, :, :]               # most recent frame\n",
    "        output = torch.clamp(latest + residual, 0.0, 1.0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Create model instance\n",
    "model = RealTimePongPredictor()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB (FP32)\")\n",
    "\n",
    "# Test inference speed\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Benchmark inference speed\n",
    "import time\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Warmup - FIXED: Use 2 channels input as expected by the model\n",
    "    for _ in range(10):\n",
    "        dummy_input = torch.randn(1, 2, 200, 200).to(device)  # Changed to 200x200\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    # Actual timing - FIXED: Use 2 channels input as expected by the model\n",
    "    times = []\n",
    "    for _ in range(200):\n",
    "        dummy_input = torch.randn(1, 2, 200, 200).to(device)  # Changed to 200x200\n",
    "        start_time = time.time()\n",
    "        output = model(dummy_input)\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "        end_time = time.time()\n",
    "        times.append((end_time - start_time) * 1000)  # Convert to milliseconds\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    print(f\"\\nInference Performance:\")\n",
    "    print(f\"Average inference time: {avg_time:.2f} ms\")\n",
    "    print(f\"Theoretical max FPS: {1000/avg_time:.1f}\")\n",
    "    print(f\"Real-time capable (60fps): {'✓ YES' if avg_time < 16.67 else '✗ NO'}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "baf84ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6496 total frames\n",
      "Created 6494 valid sequences\n",
      "Dataset created with 6494 training pairs\n",
      "Batch size: 16\n",
      "Training batches per epoch: 406\n",
      "Sample batch shapes - Input(two): torch.Size([16, 2, 200, 200]), Target: torch.Size([16, 1, 200, 200])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class PongSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for loading consecutive Pong frames for next-frame prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, frames_dir=\"frames\", sequence_length=3):\n",
    "        self.frames_dir = Path(frames_dir)\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Get all frame files and sort them by timestamp\n",
    "        self.frame_files = sorted([f for f in self.frames_dir.glob(\"*.png\")])\n",
    "        \n",
    "        # Group frames by recording session (same timestamp prefix)\n",
    "        self.sequences = self._group_sequences()\n",
    "        \n",
    "        print(f\"Found {len(self.frame_files)} total frames\")\n",
    "        print(f\"Created {len(self.sequences)} valid sequences\")\n",
    "    \n",
    "    def _group_sequences(self):\n",
    "        \"\"\"Group frames into sequences by timestamp\"\"\"\n",
    "        sequences = []\n",
    "        current_session = []\n",
    "        current_prefix = None\n",
    "        \n",
    "        for frame_file in self.frame_files:\n",
    "            # Extract timestamp prefix (everything before the frame number)\n",
    "            parts = frame_file.stem.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                prefix = '_'.join(parts[:-1])  # All parts except the last (frame number)\n",
    "                \n",
    "                if current_prefix is None or prefix == current_prefix:\n",
    "                    current_session.append(frame_file)\n",
    "                    current_prefix = prefix\n",
    "                else:\n",
    "                    # New session started, process previous session\n",
    "                    if len(current_session) >= self.sequence_length:\n",
    "                        for i in range(len(current_session) - self.sequence_length + 1):\n",
    "                            sequences.append(current_session[i:i + self.sequence_length])\n",
    "                    \n",
    "                    # Start new session\n",
    "                    current_session = [frame_file]\n",
    "                    current_prefix = prefix\n",
    "        \n",
    "        # Process the last session\n",
    "        if len(current_session) >= self.sequence_length:\n",
    "            for i in range(len(current_session) - self.sequence_length + 1):\n",
    "                sequences.append(current_session[i:i + self.sequence_length])\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        # Load frames as tensors\n",
    "        frames = []\n",
    "        for frame_file in sequence:\n",
    "            img = Image.open(frame_file)\n",
    "            # Convert to grayscale tensor\n",
    "            img_array = np.array(img)\n",
    "            if len(img_array.shape) == 3:\n",
    "                img_array = img_array[:, :, 0]  # Use first channel\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            tensor = torch.from_numpy(img_array.astype(np.float32)) / 255.0\n",
    "            frames.append(tensor.unsqueeze(0))  # Add channel dimension\n",
    "        \n",
    "        # Return two input frames and target frame: (t-1, t) -> t+1\n",
    "        prev_frame = frames[0]\n",
    "        curr_frame = frames[1]\n",
    "        target_frame = frames[2]\n",
    "        \n",
    "        input_two = torch.cat([prev_frame, curr_frame], dim=0)  # [2, H, W]\n",
    "        return input_two, target_frame\n",
    "\n",
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 1e-3\n",
    "        self.num_epochs = 10\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.save_every = 5  # Save model every N epochs\n",
    "        \n",
    "config = TrainingConfig()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "try:\n",
    "    dataset = PongSequenceDataset(frames_dir=\"frames\")\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    print(f\"Dataset created with {len(dataset)} training pairs\")\n",
    "    print(f\"Batch size: {config.batch_size}\")\n",
    "    print(f\"Training batches per epoch: {len(dataloader)}\")\n",
    "    \n",
    "    # Test loading a batch\n",
    "    sample_input, sample_target = next(iter(dataloader))\n",
    "    print(f\"Sample batch shapes - Input(two): {sample_input.shape}, Target: {sample_target.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not create dataset: {e}\")\n",
    "    print(\"Make sure you have recorded some frames using F1 in the Pong game!\")\n",
    "    dataset = None\n",
    "    dataloader = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8d24b230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training setup complete!\n",
      "\n",
      "To start training, run:\n",
      "trained_model = train_model(model, dataloader, config)\n",
      "\n",
      "To visualize predictions:\n",
      "visualize_predictions(model, dataloader, config)\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, dataloader, config):\n",
    "    \"\"\"\n",
    "    Training loop for the Pong frame prediction model\n",
    "    \"\"\"\n",
    "    if dataloader is None:\n",
    "        print(\"No dataloader available. Please record some frames first!\")\n",
    "        return\n",
    "    \n",
    "    # Setup training\n",
    "    model = model.to(config.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Weighted loss to emphasize white pixels (includes bottom row)\n",
    "    def weighted_l1_loss(predicted: torch.Tensor, target: torch.Tensor, white_weight: float = 4.0) -> torch.Tensor:\n",
    "        # target in [0,1]; weight white/intense pixels more\n",
    "        weights = 1.0 + white_weight * target\n",
    "        return torch.mean(weights * torch.abs(predicted - target))\n",
    "    \n",
    "    criterion = weighted_l1_loss\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    print(f\"Starting training on {config.device}\")\n",
    "    print(f\"Training for {config.num_epochs} epochs with {len(dataloader)} batches per epoch\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (input_frames, target_frames) in enumerate(dataloader):\n",
    "            # Move to device\n",
    "            input_frames = input_frames.to(config.device)       # [B, 2, H, W]\n",
    "            target_frames = target_frames.to(config.device)     # [B, 1, H, W]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            predicted_frames = model(input_frames)\n",
    "            \n",
    "            # Calculate loss (both in [0,1])\n",
    "            loss = criterion(predicted_frames, target_frames)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Print progress every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{config.num_epochs}, \"\n",
    "                      f\"Batch {batch_idx}/{len(dataloader)}, \"\n",
    "                      f\"Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} completed - Average Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % config.save_every == 0:\n",
    "            checkpoint_path = f\"pong_model_epoch_{epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = \"pong_model_final.pth\"\n",
    "    torch.save(model.state_dict(), final_path)\n",
    "    print(f\"Training completed! Final model saved as: {final_path}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to visualize predictions\n",
    "def visualize_predictions(model, dataloader, config, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualize model predictions vs ground truth\n",
    "    \"\"\"\n",
    "    if dataloader is None:\n",
    "        print(\"No dataloader available for visualization!\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get a batch of samples\n",
    "        input_frames, target_frames = next(iter(dataloader))\n",
    "        input_frames = input_frames.to(config.device)\n",
    "        target_frames = target_frames.to(config.device)\n",
    "        \n",
    "        # Make predictions\n",
    "        predicted_frames = model(input_frames)\n",
    "        \n",
    "        # Move to CPU for visualization\n",
    "        input_frames = input_frames.cpu()\n",
    "        target_frames = target_frames.cpu()\n",
    "        predicted_frames = predicted_frames.cpu()\n",
    "        \n",
    "        # Plot comparisons\n",
    "        fig, axes = plt.subplots(3, min(num_samples, len(input_frames)), figsize=(15, 9))\n",
    "        if min(num_samples, len(input_frames)) == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        for i in range(min(num_samples, len(input_frames))):\n",
    "            # Input frame\n",
    "            axes[0, i].imshow(input_frames[i, 1], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[0, i].set_title(f\"Input t (latest) {i+1}\")\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Ground truth next frame\n",
    "            axes[1, i].imshow(target_frames[i, 0], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[1, i].set_title(f\"Ground Truth {i+1}\")\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            # Predicted next frame\n",
    "            pred_frame = predicted_frames[i, 0]  # Already in [0,1]\n",
    "            axes[2, i].imshow(pred_frame, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[2, i].set_title(f\"Predicted {i+1}\")\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate and print metrics\n",
    "        mse = F.mse_loss(predicted_frames, target_frames).item()\n",
    "        mae = F.l1_loss(predicted_frames, target_frames).item()\n",
    "        \n",
    "        print(f\"Prediction Metrics:\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Ready to train!\n",
    "print(\"Training setup complete!\")\n",
    "print(\"\\nTo start training, run:\")\n",
    "print(\"trained_model = train_model(model, dataloader, config)\")\n",
    "print(\"\\nTo visualize predictions:\")\n",
    "print(\"visualize_predictions(model, dataloader, config)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8bfc0568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model path provided or file not found. Using randomly initialized model.\n",
      "Enabled CUDNN optimizations\n",
      "Warming up model...\n",
      "Warmup complete!\n",
      "\n",
      "Inference Benchmark Results (1000 iterations):\n",
      "Average time: 2.34 ± 0.62 ms\n",
      "Min time: 1.67 ms\n",
      "Max time: 10.21 ms\n",
      "Theoretical max FPS: 428.1\n",
      "Real-time capable (60fps): ✓ YES\n",
      "Real-time capable (30fps): ✓ YES\n",
      "\n",
      "============================================================\n",
      "REAL-TIME GENERATIVE PONG MODEL READY!\n",
      "============================================================\n",
      "Model size: ~7.4 MB\n",
      "Inference time: 2.34 ms\n",
      "Device: cuda\n",
      "\n",
      "Next steps:\n",
      "1. Record training data: Play Pong and press F1 to record frames\n",
      "2. Train the model: trained_model = train_model(model, dataloader, config)\n",
      "3. Create generative gameplay integration\n"
     ]
    }
   ],
   "source": [
    "class RealTimeInference:\n",
    "    \"\"\"\n",
    "    Optimized inference class for real-time gameplay\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=None, device=None):\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        # Create model\n",
    "        self.model = RealTimePongPredictor()\n",
    "        \n",
    "        # Load trained weights if available\n",
    "        if model_path and Path(model_path).exists():\n",
    "            try:\n",
    "                state_dict = torch.load(model_path, map_location=self.device)\n",
    "                self.model.load_state_dict(state_dict)\n",
    "                print(f\"Loaded model from {model_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load model from {model_path}: {e}\")\n",
    "                print(\"Using randomly initialized model\")\n",
    "        else:\n",
    "            print(\"No model path provided or file not found. Using randomly initialized model.\")\n",
    "        \n",
    "        # Optimize for inference\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Enable optimizations\n",
    "        if torch.cuda.is_available():\n",
    "            # Enable TensorRT optimizations if available\n",
    "            try:\n",
    "                import torch.backends.cudnn as cudnn\n",
    "                cudnn.benchmark = True\n",
    "                cudnn.deterministic = False\n",
    "                print(\"Enabled CUDNN optimizations\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Pre-allocate tensors for inference\n",
    "        self.input_tensor = torch.zeros(1, 2, 200, 200, device=self.device)\n",
    "        \n",
    "        # Warmup the model\n",
    "        self._warmup()\n",
    "        \n",
    "    def _warmup(self, warmup_iterations=50):\n",
    "        \"\"\"Warmup the model for consistent timing\"\"\"\n",
    "        print(\"Warming up model...\")\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warmup_iterations):\n",
    "                dummy_input = torch.randn(1, 2, 200, 200, device=self.device)\n",
    "                _ = self.model(dummy_input)\n",
    "        print(\"Warmup complete!\")\n",
    "    \n",
    "    def predict_next_frame(self, prev_frame_np, current_frame_np, controls=None):\n",
    "        \"\"\"\n",
    "        Predict next frame from current frame\n",
    "        \n",
    "        Args:\n",
    "            prev_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "            current_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "            controls: dict with 'up' and 'down' boolean keys (optional)\n",
    "                     If provided, will overwrite the bottom row pixels\n",
    "        \n",
    "        Returns:\n",
    "            next_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Convert numpy to tensor\n",
    "            prev_tensor = torch.from_numpy(prev_frame_np.astype(np.float32)) / 255.0\n",
    "            curr_tensor = torch.from_numpy(current_frame_np.astype(np.float32)) / 255.0\n",
    "            prev_tensor = prev_tensor.unsqueeze(0).unsqueeze(0)\n",
    "            curr_tensor = curr_tensor.unsqueeze(0).unsqueeze(0)\n",
    "            frame_tensor = torch.cat([prev_tensor, curr_tensor], dim=1).to(self.device)  # [1,2,100,100]\n",
    "            \n",
    "            # Apply control encoding if provided (overwrite on latest frame channel)\n",
    "            if controls is not None:\n",
    "                bottom_row = torch.zeros(1, 1, 1, 200, device=self.device)\n",
    "                if controls.get('up', False):\n",
    "                    bottom_row[0, 0, 0, :50] = 1.0\n",
    "                if controls.get('down', False):\n",
    "                    bottom_row[0, 0, 0, 50:] = 1.0\n",
    "                frame_tensor[:, 1:2, -1:, :] = bottom_row\n",
    "            \n",
    "            # Predict next frame\n",
    "            prediction = self.model(frame_tensor)\n",
    "            \n",
    "            # Convert back to numpy\n",
    "            prediction_np = prediction[0, 0].cpu().numpy()  # Remove batch and channel dims\n",
    "            prediction_np = np.clip(prediction_np * 255.0, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            return prediction_np\n",
    "    \n",
    "    def benchmark_inference(self, iterations=1000):\n",
    "        \"\"\"Benchmark inference speed\"\"\"\n",
    "        times = []\n",
    "        dummy_prev_frame = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
    "        dummy_curr_frame = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            start_time = time.time()\n",
    "            _ = self.predict_next_frame(dummy_prev_frame, dummy_curr_frame)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        min_time = np.min(times)\n",
    "        max_time = np.max(times)\n",
    "        \n",
    "        print(f\"\\nInference Benchmark Results ({iterations} iterations):\")\n",
    "        print(f\"Average time: {avg_time:.2f} ± {std_time:.2f} ms\")\n",
    "        print(f\"Min time: {min_time:.2f} ms\")\n",
    "        print(f\"Max time: {max_time:.2f} ms\")\n",
    "        print(f\"Theoretical max FPS: {1000/avg_time:.1f}\")\n",
    "        print(f\"Real-time capable (60fps): {'✓ YES' if avg_time < 16.67 else '✗ NO'}\")\n",
    "        print(f\"Real-time capable (30fps): {'✓ YES' if avg_time < 33.33 else '✗ NO'}\")\n",
    "        \n",
    "        return avg_time\n",
    "\n",
    "# Create inference engine\n",
    "inference_engine = RealTimeInference()\n",
    "\n",
    "# Benchmark performance\n",
    "inference_time = inference_engine.benchmark_inference()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"REAL-TIME GENERATIVE PONG MODEL READY!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Model size: ~{sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Inference time: {inference_time:.2f} ms\")\n",
    "print(f\"Device: {inference_engine.device}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Record training data: Play Pong and press F1 to record frames\")\n",
    "print(\"2. Train the model: trained_model = train_model(model, dataloader, config)\")\n",
    "print(\"3. Create generative gameplay integration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6efc0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "# ===== Continuous Generative Gameplay (ignores controls) =====\n",
    "\n",
    "def find_model_path():\n",
    "    \"\"\"Return best available model path (final first, else latest epoch).\"\"\"\n",
    "    final_path = Path(\"pong_model_final.pth\")\n",
    "    if final_path.exists():\n",
    "        return str(final_path)\n",
    "    # Fallback: latest epoch checkpoint\n",
    "    ckpts = sorted(glob.glob(\"pong_model_epoch_*.pth\"))\n",
    "    return ckpts[-1] if ckpts else None\n",
    "\n",
    "\n",
    "def robust_load_into_inference(inf_engine: RealTimeInference, model_path: str):\n",
    "    \"\"\"Load either a raw state_dict or a checkpoint dict into the inference model.\"\"\"\n",
    "    if not model_path:\n",
    "        print(\"No trained model found. Using random weights (results will be nonsense).\")\n",
    "        return\n",
    "    try:\n",
    "        state = torch.load(model_path, map_location=inf_engine.device)\n",
    "        # Check for checkpoint vs raw state_dict\n",
    "        if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "            inf_engine.model.load_state_dict(state[\"model_state_dict\"])\n",
    "            print(f\"Loaded checkpoint weights from: {model_path}\")\n",
    "        else:\n",
    "            inf_engine.model.load_state_dict(state)\n",
    "            print(f\"Loaded state_dict from: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model from {model_path}: {e}\")\n",
    "        print(\"Continuing with randomly initialized model.\")\n",
    "\n",
    "\n",
    "def get_seed_frame(frames_dir=\"frames\"):\n",
    "    \"\"\"Pick a seed frame if available, else create a simple synthetic seed.\"\"\"\n",
    "    if os.path.isdir(frames_dir):\n",
    "        pngs = sorted([p for p in os.listdir(frames_dir) if p.endswith('.png')])\n",
    "        if pngs:\n",
    "            seed_path = os.path.join(frames_dir, pngs[0])\n",
    "            img = Image.open(seed_path).convert(\"L\")\n",
    "            return np.array(img, dtype=np.uint8)\n",
    "    # Create synthetic seed: paddles center, ball center, bottom row off\n",
    "    frame = np.zeros((200, 200), dtype=np.uint8)\n",
    "    # left paddle (player)\n",
    "    frame[82:118, 10:16] = 255\n",
    "    # right paddle (AI)\n",
    "    frame[82:118, 184:190] = 255\n",
    "    # ball\n",
    "    frame[97:103, 97:103] = 255\n",
    "    # bottom row zeros (controls off)\n",
    "    frame[-1, :] = 0\n",
    "    return frame\n",
    "\n",
    "\n",
    "def generate_gameplay(output_dir=None, num_frames=1200, save_video=True, fps=60, model_path=None):\n",
    "    \"\"\"\n",
    "    Generate continuous frames by feeding model outputs back as inputs.\n",
    "    Controls are ignored (bottom row forced to zero each step).\n",
    "    \"\"\"\n",
    "    # Prepare output directory\n",
    "    if output_dir is None:\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_dir = Path(f\"generated_{ts}\")\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create inference engine and load trained weights\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    inf = RealTimeInference(model_path=None, device=device)\n",
    "    if model_path is None:\n",
    "        model_path = find_model_path()\n",
    "    robust_load_into_inference(inf, model_path)\n",
    "\n",
    "    # Get seed\n",
    "    # Bootstrap two frames: duplicate seed as both prev and current to start\n",
    "    prev = get_seed_frame()\n",
    "    current = prev.copy()\n",
    "\n",
    "    # Optional video writer\n",
    "    writer = None\n",
    "    video_path = output_dir / \"0gameplay.mp4\"\n",
    "    if save_video:\n",
    "        try:\n",
    "            import imageio\n",
    "            writer = imageio.get_writer(video_path, fps=fps)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not initialize video writer: {e}\")\n",
    "            print(\"Frames will still be saved as PNGs. To enable MP4, install: \\n\"\n",
    "                  \"pip install imageio[ffmpeg]\")\n",
    "\n",
    "    print(f\"Generating {num_frames} frames to: {output_dir}\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        # Force controls off by overriding bottom row via controls param\n",
    "        # Predict using (prev, curr) -> next (do not override bottom row)\n",
    "        next_frame = inf.predict_next_frame(prev, current)\n",
    "\n",
    "        # Save PNG\n",
    "        out_path = output_dir / f\"frame_{i:05d}.png\"\n",
    "        Image.fromarray(next_frame).save(out_path)\n",
    "\n",
    "        # Append to video if available\n",
    "        if writer is not None:\n",
    "            try:\n",
    "                writer.append_data(next_frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Video write error at frame {i}: {e}\")\n",
    "                writer = None  # Stop trying\n",
    "\n",
    "        # Feedback for next step (shift window)\n",
    "        prev = current\n",
    "        current = next_frame\n",
    "\n",
    "        # Light status\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Generated {i + 1}/{num_frames} frames...\")\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "        print(f\"Saved video: {video_path}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return str(output_dir)\n",
    "\n",
    "# Example run (uncomment to execute):\n",
    "# out_dir = generate_gameplay(num_frames=1800, fps=60)\n",
    "# out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "369f9b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training on cuda\n",
      "Training for 10 epochs with 406 batches per epoch\n",
      "------------------------------------------------------------\n",
      "Epoch 1/10, Batch 0/406, Loss: 0.260523\n",
      "Epoch 1/10, Batch 10/406, Loss: 0.022112\n",
      "Epoch 1/10, Batch 20/406, Loss: 0.013312\n",
      "Epoch 1/10, Batch 30/406, Loss: 0.007860\n",
      "Epoch 1/10, Batch 40/406, Loss: 0.004674\n",
      "Epoch 1/10, Batch 50/406, Loss: 0.007068\n",
      "Epoch 1/10, Batch 60/406, Loss: 0.003673\n",
      "Epoch 1/10, Batch 70/406, Loss: 0.003195\n",
      "Epoch 1/10, Batch 80/406, Loss: 0.002490\n",
      "Epoch 1/10, Batch 90/406, Loss: 0.002831\n",
      "Epoch 1/10, Batch 100/406, Loss: 0.002488\n",
      "Epoch 1/10, Batch 110/406, Loss: 0.002976\n",
      "Epoch 1/10, Batch 120/406, Loss: 0.002452\n",
      "Epoch 1/10, Batch 130/406, Loss: 0.002089\n",
      "Epoch 1/10, Batch 140/406, Loss: 0.002918\n",
      "Epoch 1/10, Batch 150/406, Loss: 0.002051\n",
      "Epoch 1/10, Batch 160/406, Loss: 0.001854\n",
      "Epoch 1/10, Batch 170/406, Loss: 0.003908\n",
      "Epoch 1/10, Batch 180/406, Loss: 0.003008\n",
      "Epoch 1/10, Batch 190/406, Loss: 0.003214\n",
      "Epoch 1/10, Batch 200/406, Loss: 0.002200\n",
      "Epoch 1/10, Batch 210/406, Loss: 0.001240\n",
      "Epoch 1/10, Batch 220/406, Loss: 0.004066\n",
      "Epoch 1/10, Batch 230/406, Loss: 0.001252\n",
      "Epoch 1/10, Batch 240/406, Loss: 0.001984\n",
      "Epoch 1/10, Batch 250/406, Loss: 0.001546\n",
      "Epoch 1/10, Batch 260/406, Loss: 0.002714\n",
      "Epoch 1/10, Batch 270/406, Loss: 0.003206\n",
      "Epoch 1/10, Batch 280/406, Loss: 0.001599\n",
      "Epoch 1/10, Batch 290/406, Loss: 0.000986\n",
      "Epoch 1/10, Batch 300/406, Loss: 0.000703\n",
      "Epoch 1/10, Batch 310/406, Loss: 0.004587\n",
      "Epoch 1/10, Batch 320/406, Loss: 0.002751\n",
      "Epoch 1/10, Batch 330/406, Loss: 0.002979\n",
      "Epoch 1/10, Batch 340/406, Loss: 0.002540\n",
      "Epoch 1/10, Batch 350/406, Loss: 0.000749\n",
      "Epoch 1/10, Batch 360/406, Loss: 0.003349\n",
      "Epoch 1/10, Batch 370/406, Loss: 0.001369\n",
      "Epoch 1/10, Batch 380/406, Loss: 0.000987\n",
      "Epoch 1/10, Batch 390/406, Loss: 0.002104\n",
      "Epoch 1/10, Batch 400/406, Loss: 0.001081\n",
      "Epoch 1 completed - Average Loss: 0.004776\n",
      "------------------------------------------------------------\n",
      "Epoch 2/10, Batch 0/406, Loss: 0.001172\n",
      "Epoch 2/10, Batch 10/406, Loss: 0.005869\n",
      "Epoch 2/10, Batch 20/406, Loss: 0.004111\n",
      "Epoch 2/10, Batch 30/406, Loss: 0.004954\n",
      "Epoch 2/10, Batch 40/406, Loss: 0.002932\n",
      "Epoch 2/10, Batch 50/406, Loss: 0.002121\n",
      "Epoch 2/10, Batch 60/406, Loss: 0.003647\n",
      "Epoch 2/10, Batch 70/406, Loss: 0.002335\n",
      "Epoch 2/10, Batch 80/406, Loss: 0.001995\n",
      "Epoch 2/10, Batch 90/406, Loss: 0.003072\n",
      "Epoch 2/10, Batch 100/406, Loss: 0.002343\n",
      "Epoch 2/10, Batch 110/406, Loss: 0.001879\n",
      "Epoch 2/10, Batch 120/406, Loss: 0.002057\n",
      "Epoch 2/10, Batch 130/406, Loss: 0.001415\n",
      "Epoch 2/10, Batch 140/406, Loss: 0.001390\n",
      "Epoch 2/10, Batch 150/406, Loss: 0.001582\n",
      "Epoch 2/10, Batch 160/406, Loss: 0.002794\n",
      "Epoch 2/10, Batch 170/406, Loss: 0.002401\n",
      "Epoch 2/10, Batch 180/406, Loss: 0.002195\n",
      "Epoch 2/10, Batch 190/406, Loss: 0.001139\n",
      "Epoch 2/10, Batch 200/406, Loss: 0.001609\n",
      "Epoch 2/10, Batch 210/406, Loss: 0.004692\n",
      "Epoch 2/10, Batch 220/406, Loss: 0.001090\n",
      "Epoch 2/10, Batch 230/406, Loss: 0.001121\n",
      "Epoch 2/10, Batch 240/406, Loss: 0.002612\n",
      "Epoch 2/10, Batch 250/406, Loss: 0.001219\n",
      "Epoch 2/10, Batch 260/406, Loss: 0.002596\n",
      "Epoch 2/10, Batch 270/406, Loss: 0.001521\n",
      "Epoch 2/10, Batch 280/406, Loss: 0.001240\n",
      "Epoch 2/10, Batch 290/406, Loss: 0.001287\n",
      "Epoch 2/10, Batch 300/406, Loss: 0.002402\n",
      "Epoch 2/10, Batch 310/406, Loss: 0.001427\n",
      "Epoch 2/10, Batch 320/406, Loss: 0.000887\n",
      "Epoch 2/10, Batch 330/406, Loss: 0.001130\n",
      "Epoch 2/10, Batch 340/406, Loss: 0.000876\n",
      "Epoch 2/10, Batch 350/406, Loss: 0.002870\n",
      "Epoch 2/10, Batch 360/406, Loss: 0.000655\n",
      "Epoch 2/10, Batch 370/406, Loss: 0.001313\n",
      "Epoch 2/10, Batch 380/406, Loss: 0.000853\n",
      "Epoch 2/10, Batch 390/406, Loss: 0.000717\n",
      "Epoch 2/10, Batch 400/406, Loss: 0.000900\n",
      "Epoch 2 completed - Average Loss: 0.002371\n",
      "------------------------------------------------------------\n",
      "Epoch 3/10, Batch 0/406, Loss: 0.002178\n",
      "Epoch 3/10, Batch 10/406, Loss: 0.000754\n",
      "Epoch 3/10, Batch 20/406, Loss: 0.001223\n",
      "Epoch 3/10, Batch 30/406, Loss: 0.002338\n",
      "Epoch 3/10, Batch 40/406, Loss: 0.000660\n",
      "Epoch 3/10, Batch 50/406, Loss: 0.002335\n",
      "Epoch 3/10, Batch 60/406, Loss: 0.002917\n",
      "Epoch 3/10, Batch 70/406, Loss: 0.002669\n",
      "Epoch 3/10, Batch 80/406, Loss: 0.000403\n",
      "Epoch 3/10, Batch 90/406, Loss: 0.002761\n",
      "Epoch 3/10, Batch 100/406, Loss: 0.002358\n",
      "Epoch 3/10, Batch 110/406, Loss: 0.000615\n",
      "Epoch 3/10, Batch 120/406, Loss: 0.002339\n",
      "Epoch 3/10, Batch 130/406, Loss: 0.000641\n",
      "Epoch 3/10, Batch 140/406, Loss: 0.001008\n",
      "Epoch 3/10, Batch 150/406, Loss: 0.004025\n",
      "Epoch 3/10, Batch 160/406, Loss: 0.001017\n",
      "Epoch 3/10, Batch 170/406, Loss: 0.004347\n",
      "Epoch 3/10, Batch 180/406, Loss: 0.002341\n",
      "Epoch 3/10, Batch 190/406, Loss: 0.005793\n",
      "Epoch 3/10, Batch 200/406, Loss: 0.001183\n",
      "Epoch 3/10, Batch 210/406, Loss: 0.001509\n",
      "Epoch 3/10, Batch 220/406, Loss: 0.000763\n",
      "Epoch 3/10, Batch 230/406, Loss: 0.002076\n",
      "Epoch 3/10, Batch 240/406, Loss: 0.000343\n",
      "Epoch 3/10, Batch 250/406, Loss: 0.000778\n",
      "Epoch 3/10, Batch 260/406, Loss: 0.000458\n",
      "Epoch 3/10, Batch 270/406, Loss: 0.001972\n",
      "Epoch 3/10, Batch 280/406, Loss: 0.000444\n",
      "Epoch 3/10, Batch 290/406, Loss: 0.004059\n",
      "Epoch 3/10, Batch 300/406, Loss: 0.002302\n",
      "Epoch 3/10, Batch 310/406, Loss: 0.002585\n",
      "Epoch 3/10, Batch 320/406, Loss: 0.000430\n",
      "Epoch 3/10, Batch 330/406, Loss: 0.000273\n",
      "Epoch 3/10, Batch 340/406, Loss: 0.002294\n",
      "Epoch 3/10, Batch 350/406, Loss: 0.002343\n",
      "Epoch 3/10, Batch 360/406, Loss: 0.001079\n",
      "Epoch 3/10, Batch 370/406, Loss: 0.001247\n",
      "Epoch 3/10, Batch 380/406, Loss: 0.004864\n",
      "Epoch 3/10, Batch 390/406, Loss: 0.000809\n",
      "Epoch 3/10, Batch 400/406, Loss: 0.001645\n",
      "Epoch 3 completed - Average Loss: 0.001580\n",
      "------------------------------------------------------------\n",
      "Epoch 4/10, Batch 0/406, Loss: 0.000676\n",
      "Epoch 4/10, Batch 10/406, Loss: 0.002510\n",
      "Epoch 4/10, Batch 20/406, Loss: 0.003706\n",
      "Epoch 4/10, Batch 30/406, Loss: 0.000939\n",
      "Epoch 4/10, Batch 40/406, Loss: 0.000799\n",
      "Epoch 4/10, Batch 50/406, Loss: 0.001301\n",
      "Epoch 4/10, Batch 60/406, Loss: 0.001405\n",
      "Epoch 4/10, Batch 70/406, Loss: 0.000249\n",
      "Epoch 4/10, Batch 80/406, Loss: 0.001047\n",
      "Epoch 4/10, Batch 90/406, Loss: 0.002281\n",
      "Epoch 4/10, Batch 100/406, Loss: 0.000532\n",
      "Epoch 4/10, Batch 110/406, Loss: 0.001999\n",
      "Epoch 4/10, Batch 120/406, Loss: 0.002796\n",
      "Epoch 4/10, Batch 130/406, Loss: 0.004033\n",
      "Epoch 4/10, Batch 140/406, Loss: 0.000911\n",
      "Epoch 4/10, Batch 150/406, Loss: 0.001454\n",
      "Epoch 4/10, Batch 160/406, Loss: 0.002487\n",
      "Epoch 4/10, Batch 170/406, Loss: 0.001146\n",
      "Epoch 4/10, Batch 180/406, Loss: 0.003751\n",
      "Epoch 4/10, Batch 190/406, Loss: 0.000717\n",
      "Epoch 4/10, Batch 200/406, Loss: 0.000673\n",
      "Epoch 4/10, Batch 210/406, Loss: 0.000568\n",
      "Epoch 4/10, Batch 220/406, Loss: 0.000756\n",
      "Epoch 4/10, Batch 230/406, Loss: 0.004723\n",
      "Epoch 4/10, Batch 240/406, Loss: 0.002001\n",
      "Epoch 4/10, Batch 250/406, Loss: 0.000891\n",
      "Epoch 4/10, Batch 260/406, Loss: 0.000859\n",
      "Epoch 4/10, Batch 270/406, Loss: 0.000331\n",
      "Epoch 4/10, Batch 280/406, Loss: 0.001195\n",
      "Epoch 4/10, Batch 290/406, Loss: 0.000244\n",
      "Epoch 4/10, Batch 300/406, Loss: 0.000225\n",
      "Epoch 4/10, Batch 310/406, Loss: 0.002297\n",
      "Epoch 4/10, Batch 320/406, Loss: 0.000525\n",
      "Epoch 4/10, Batch 330/406, Loss: 0.000349\n",
      "Epoch 4/10, Batch 340/406, Loss: 0.003610\n",
      "Epoch 4/10, Batch 350/406, Loss: 0.000628\n",
      "Epoch 4/10, Batch 360/406, Loss: 0.000480\n",
      "Epoch 4/10, Batch 370/406, Loss: 0.000317\n",
      "Epoch 4/10, Batch 380/406, Loss: 0.000298\n",
      "Epoch 4/10, Batch 390/406, Loss: 0.004804\n",
      "Epoch 4/10, Batch 400/406, Loss: 0.000824\n",
      "Epoch 4 completed - Average Loss: 0.001414\n",
      "------------------------------------------------------------\n",
      "Epoch 5/10, Batch 0/406, Loss: 0.002183\n",
      "Epoch 5/10, Batch 10/406, Loss: 0.000460\n",
      "Epoch 5/10, Batch 20/406, Loss: 0.001189\n",
      "Epoch 5/10, Batch 30/406, Loss: 0.002358\n",
      "Epoch 5/10, Batch 40/406, Loss: 0.001181\n",
      "Epoch 5/10, Batch 50/406, Loss: 0.000687\n",
      "Epoch 5/10, Batch 60/406, Loss: 0.001003\n",
      "Epoch 5/10, Batch 70/406, Loss: 0.002407\n",
      "Epoch 5/10, Batch 80/406, Loss: 0.000680\n",
      "Epoch 5/10, Batch 90/406, Loss: 0.000331\n",
      "Epoch 5/10, Batch 100/406, Loss: 0.000651\n",
      "Epoch 5/10, Batch 110/406, Loss: 0.000417\n",
      "Epoch 5/10, Batch 120/406, Loss: 0.000641\n",
      "Epoch 5/10, Batch 130/406, Loss: 0.000301\n",
      "Epoch 5/10, Batch 140/406, Loss: 0.000908\n",
      "Epoch 5/10, Batch 150/406, Loss: 0.000979\n",
      "Epoch 5/10, Batch 160/406, Loss: 0.002028\n",
      "Epoch 5/10, Batch 170/406, Loss: 0.000141\n",
      "Epoch 5/10, Batch 180/406, Loss: 0.001573\n",
      "Epoch 5/10, Batch 190/406, Loss: 0.004194\n",
      "Epoch 5/10, Batch 200/406, Loss: 0.000412\n",
      "Epoch 5/10, Batch 210/406, Loss: 0.000233\n",
      "Epoch 5/10, Batch 220/406, Loss: 0.000596\n",
      "Epoch 5/10, Batch 230/406, Loss: 0.002443\n",
      "Epoch 5/10, Batch 240/406, Loss: 0.002403\n",
      "Epoch 5/10, Batch 250/406, Loss: 0.002253\n",
      "Epoch 5/10, Batch 260/406, Loss: 0.003063\n",
      "Epoch 5/10, Batch 270/406, Loss: 0.001651\n",
      "Epoch 5/10, Batch 280/406, Loss: 0.002166\n",
      "Epoch 5/10, Batch 290/406, Loss: 0.000486\n",
      "Epoch 5/10, Batch 300/406, Loss: 0.001206\n",
      "Epoch 5/10, Batch 310/406, Loss: 0.000532\n",
      "Epoch 5/10, Batch 320/406, Loss: 0.000474\n",
      "Epoch 5/10, Batch 330/406, Loss: 0.001803\n",
      "Epoch 5/10, Batch 340/406, Loss: 0.000174\n",
      "Epoch 5/10, Batch 350/406, Loss: 0.000160\n",
      "Epoch 5/10, Batch 360/406, Loss: 0.000762\n",
      "Epoch 5/10, Batch 370/406, Loss: 0.002009\n",
      "Epoch 5/10, Batch 380/406, Loss: 0.001951\n",
      "Epoch 5/10, Batch 390/406, Loss: 0.000167\n",
      "Epoch 5/10, Batch 400/406, Loss: 0.000606\n",
      "Epoch 5 completed - Average Loss: 0.001352\n",
      "Saved checkpoint: pong_model_epoch_5.pth\n",
      "------------------------------------------------------------\n",
      "Epoch 6/10, Batch 0/406, Loss: 0.003905\n",
      "Epoch 6/10, Batch 10/406, Loss: 0.000891\n",
      "Epoch 6/10, Batch 20/406, Loss: 0.000122\n",
      "Epoch 6/10, Batch 30/406, Loss: 0.000343\n",
      "Epoch 6/10, Batch 40/406, Loss: 0.002359\n",
      "Epoch 6/10, Batch 50/406, Loss: 0.002630\n",
      "Epoch 6/10, Batch 60/406, Loss: 0.001960\n",
      "Epoch 6/10, Batch 70/406, Loss: 0.001920\n",
      "Epoch 6/10, Batch 80/406, Loss: 0.000646\n",
      "Epoch 6/10, Batch 90/406, Loss: 0.002100\n",
      "Epoch 6/10, Batch 100/406, Loss: 0.000849\n",
      "Epoch 6/10, Batch 110/406, Loss: 0.000366\n",
      "Epoch 6/10, Batch 120/406, Loss: 0.000809\n",
      "Epoch 6/10, Batch 130/406, Loss: 0.001089\n",
      "Epoch 6/10, Batch 140/406, Loss: 0.000541\n",
      "Epoch 6/10, Batch 150/406, Loss: 0.000874\n",
      "Epoch 6/10, Batch 160/406, Loss: 0.002343\n",
      "Epoch 6/10, Batch 170/406, Loss: 0.000624\n",
      "Epoch 6/10, Batch 180/406, Loss: 0.000644\n",
      "Epoch 6/10, Batch 190/406, Loss: 0.002082\n",
      "Epoch 6/10, Batch 200/406, Loss: 0.000157\n",
      "Epoch 6/10, Batch 210/406, Loss: 0.000516\n",
      "Epoch 6/10, Batch 220/406, Loss: 0.001997\n",
      "Epoch 6/10, Batch 230/406, Loss: 0.001851\n",
      "Epoch 6/10, Batch 240/406, Loss: 0.000511\n",
      "Epoch 6/10, Batch 250/406, Loss: 0.000578\n",
      "Epoch 6/10, Batch 260/406, Loss: 0.001045\n",
      "Epoch 6/10, Batch 270/406, Loss: 0.000550\n",
      "Epoch 6/10, Batch 280/406, Loss: 0.000512\n",
      "Epoch 6/10, Batch 290/406, Loss: 0.001988\n",
      "Epoch 6/10, Batch 300/406, Loss: 0.000162\n",
      "Epoch 6/10, Batch 310/406, Loss: 0.000291\n",
      "Epoch 6/10, Batch 320/406, Loss: 0.000360\n",
      "Epoch 6/10, Batch 330/406, Loss: 0.000859\n",
      "Epoch 6/10, Batch 340/406, Loss: 0.001295\n",
      "Epoch 6/10, Batch 350/406, Loss: 0.003564\n",
      "Epoch 6/10, Batch 360/406, Loss: 0.000527\n",
      "Epoch 6/10, Batch 370/406, Loss: 0.002265\n",
      "Epoch 6/10, Batch 380/406, Loss: 0.000231\n",
      "Epoch 6/10, Batch 390/406, Loss: 0.003755\n",
      "Epoch 6/10, Batch 400/406, Loss: 0.004300\n",
      "Epoch 6 completed - Average Loss: 0.001301\n",
      "------------------------------------------------------------\n",
      "Epoch 7/10, Batch 0/406, Loss: 0.000196\n",
      "Epoch 7/10, Batch 10/406, Loss: 0.001835\n",
      "Epoch 7/10, Batch 20/406, Loss: 0.000332\n",
      "Epoch 7/10, Batch 30/406, Loss: 0.000189\n",
      "Epoch 7/10, Batch 40/406, Loss: 0.000149\n",
      "Epoch 7/10, Batch 50/406, Loss: 0.001969\n",
      "Epoch 7/10, Batch 60/406, Loss: 0.000336\n",
      "Epoch 7/10, Batch 70/406, Loss: 0.000775\n",
      "Epoch 7/10, Batch 80/406, Loss: 0.000669\n",
      "Epoch 7/10, Batch 90/406, Loss: 0.000689\n",
      "Epoch 7/10, Batch 100/406, Loss: 0.001050\n",
      "Epoch 7/10, Batch 110/406, Loss: 0.001389\n",
      "Epoch 7/10, Batch 120/406, Loss: 0.002142\n",
      "Epoch 7/10, Batch 130/406, Loss: 0.002471\n",
      "Epoch 7/10, Batch 140/406, Loss: 0.000605\n",
      "Epoch 7/10, Batch 150/406, Loss: 0.000226\n",
      "Epoch 7/10, Batch 160/406, Loss: 0.001581\n",
      "Epoch 7/10, Batch 170/406, Loss: 0.000322\n",
      "Epoch 7/10, Batch 180/406, Loss: 0.001985\n",
      "Epoch 7/10, Batch 190/406, Loss: 0.003978\n",
      "Epoch 7/10, Batch 200/406, Loss: 0.002410\n",
      "Epoch 7/10, Batch 210/406, Loss: 0.002382\n",
      "Epoch 7/10, Batch 220/406, Loss: 0.001907\n",
      "Epoch 7/10, Batch 230/406, Loss: 0.001030\n",
      "Epoch 7/10, Batch 240/406, Loss: 0.002600\n",
      "Epoch 7/10, Batch 250/406, Loss: 0.003104\n",
      "Epoch 7/10, Batch 260/406, Loss: 0.002235\n",
      "Epoch 7/10, Batch 270/406, Loss: 0.001208\n",
      "Epoch 7/10, Batch 280/406, Loss: 0.002758\n",
      "Epoch 7/10, Batch 290/406, Loss: 0.002816\n",
      "Epoch 7/10, Batch 300/406, Loss: 0.000439\n",
      "Epoch 7/10, Batch 310/406, Loss: 0.002002\n",
      "Epoch 7/10, Batch 320/406, Loss: 0.000544\n",
      "Epoch 7/10, Batch 330/406, Loss: 0.000626\n",
      "Epoch 7/10, Batch 340/406, Loss: 0.000360\n",
      "Epoch 7/10, Batch 350/406, Loss: 0.000987\n",
      "Epoch 7/10, Batch 360/406, Loss: 0.000722\n",
      "Epoch 7/10, Batch 370/406, Loss: 0.000538\n",
      "Epoch 7/10, Batch 380/406, Loss: 0.000445\n",
      "Epoch 7/10, Batch 390/406, Loss: 0.000466\n",
      "Epoch 7/10, Batch 400/406, Loss: 0.002187\n",
      "Epoch 7 completed - Average Loss: 0.001547\n",
      "------------------------------------------------------------\n",
      "Epoch 8/10, Batch 0/406, Loss: 0.000670\n",
      "Epoch 8/10, Batch 10/406, Loss: 0.000375\n",
      "Epoch 8/10, Batch 20/406, Loss: 0.002195\n",
      "Epoch 8/10, Batch 30/406, Loss: 0.000284\n",
      "Epoch 8/10, Batch 40/406, Loss: 0.002097\n",
      "Epoch 8/10, Batch 50/406, Loss: 0.003707\n",
      "Epoch 8/10, Batch 60/406, Loss: 0.000684\n",
      "Epoch 8/10, Batch 70/406, Loss: 0.000653\n",
      "Epoch 8/10, Batch 80/406, Loss: 0.000410\n",
      "Epoch 8/10, Batch 90/406, Loss: 0.001468\n",
      "Epoch 8/10, Batch 100/406, Loss: 0.002004\n",
      "Epoch 8/10, Batch 110/406, Loss: 0.000286\n",
      "Epoch 8/10, Batch 120/406, Loss: 0.002798\n",
      "Epoch 8/10, Batch 130/406, Loss: 0.003296\n",
      "Epoch 8/10, Batch 140/406, Loss: 0.000777\n",
      "Epoch 8/10, Batch 150/406, Loss: 0.000741\n",
      "Epoch 8/10, Batch 160/406, Loss: 0.000288\n",
      "Epoch 8/10, Batch 170/406, Loss: 0.002272\n",
      "Epoch 8/10, Batch 180/406, Loss: 0.000256\n",
      "Epoch 8/10, Batch 190/406, Loss: 0.002065\n",
      "Epoch 8/10, Batch 200/406, Loss: 0.000820\n",
      "Epoch 8/10, Batch 210/406, Loss: 0.005761\n",
      "Epoch 8/10, Batch 220/406, Loss: 0.001121\n",
      "Epoch 8/10, Batch 230/406, Loss: 0.000645\n",
      "Epoch 8/10, Batch 240/406, Loss: 0.001903\n",
      "Epoch 8/10, Batch 250/406, Loss: 0.002400\n",
      "Epoch 8/10, Batch 260/406, Loss: 0.000664\n",
      "Epoch 8/10, Batch 270/406, Loss: 0.002465\n",
      "Epoch 8/10, Batch 280/406, Loss: 0.000494\n",
      "Epoch 8/10, Batch 290/406, Loss: 0.000647\n",
      "Epoch 8/10, Batch 300/406, Loss: 0.002921\n",
      "Epoch 8/10, Batch 310/406, Loss: 0.000810\n",
      "Epoch 8/10, Batch 320/406, Loss: 0.000265\n",
      "Epoch 8/10, Batch 330/406, Loss: 0.001749\n",
      "Epoch 8/10, Batch 340/406, Loss: 0.000138\n",
      "Epoch 8/10, Batch 350/406, Loss: 0.000383\n",
      "Epoch 8/10, Batch 360/406, Loss: 0.001837\n",
      "Epoch 8/10, Batch 370/406, Loss: 0.001817\n",
      "Epoch 8/10, Batch 380/406, Loss: 0.000277\n",
      "Epoch 8/10, Batch 390/406, Loss: 0.002290\n",
      "Epoch 8/10, Batch 400/406, Loss: 0.000589\n",
      "Epoch 8 completed - Average Loss: 0.001342\n",
      "------------------------------------------------------------\n",
      "Epoch 9/10, Batch 0/406, Loss: 0.002615\n",
      "Epoch 9/10, Batch 10/406, Loss: 0.000232\n",
      "Epoch 9/10, Batch 20/406, Loss: 0.000805\n",
      "Epoch 9/10, Batch 30/406, Loss: 0.000259\n",
      "Epoch 9/10, Batch 40/406, Loss: 0.002065\n",
      "Epoch 9/10, Batch 50/406, Loss: 0.003292\n",
      "Epoch 9/10, Batch 60/406, Loss: 0.000902\n",
      "Epoch 9/10, Batch 70/406, Loss: 0.000726\n",
      "Epoch 9/10, Batch 80/406, Loss: 0.000160\n",
      "Epoch 9/10, Batch 90/406, Loss: 0.000365\n",
      "Epoch 9/10, Batch 100/406, Loss: 0.000344\n",
      "Epoch 9/10, Batch 110/406, Loss: 0.000206\n",
      "Epoch 9/10, Batch 120/406, Loss: 0.000761\n",
      "Epoch 9/10, Batch 130/406, Loss: 0.000599\n",
      "Epoch 9/10, Batch 140/406, Loss: 0.000292\n",
      "Epoch 9/10, Batch 150/406, Loss: 0.000346\n",
      "Epoch 9/10, Batch 160/406, Loss: 0.000164\n",
      "Epoch 9/10, Batch 170/406, Loss: 0.001813\n",
      "Epoch 9/10, Batch 180/406, Loss: 0.002795\n",
      "Epoch 9/10, Batch 190/406, Loss: 0.000330\n",
      "Epoch 9/10, Batch 200/406, Loss: 0.000806\n",
      "Epoch 9/10, Batch 210/406, Loss: 0.000717\n",
      "Epoch 9/10, Batch 220/406, Loss: 0.003810\n",
      "Epoch 9/10, Batch 230/406, Loss: 0.001961\n",
      "Epoch 9/10, Batch 240/406, Loss: 0.000561\n",
      "Epoch 9/10, Batch 250/406, Loss: 0.002524\n",
      "Epoch 9/10, Batch 260/406, Loss: 0.002423\n",
      "Epoch 9/10, Batch 270/406, Loss: 0.002205\n",
      "Epoch 9/10, Batch 280/406, Loss: 0.001327\n",
      "Epoch 9/10, Batch 290/406, Loss: 0.001913\n",
      "Epoch 9/10, Batch 300/406, Loss: 0.001378\n",
      "Epoch 9/10, Batch 310/406, Loss: 0.000723\n",
      "Epoch 9/10, Batch 320/406, Loss: 0.000126\n",
      "Epoch 9/10, Batch 330/406, Loss: 0.000132\n",
      "Epoch 9/10, Batch 340/406, Loss: 0.000212\n",
      "Epoch 9/10, Batch 350/406, Loss: 0.000130\n",
      "Epoch 9/10, Batch 360/406, Loss: 0.000333\n",
      "Epoch 9/10, Batch 370/406, Loss: 0.000278\n",
      "Epoch 9/10, Batch 380/406, Loss: 0.000828\n",
      "Epoch 9/10, Batch 390/406, Loss: 0.000773\n",
      "Epoch 9/10, Batch 400/406, Loss: 0.000679\n",
      "Epoch 9 completed - Average Loss: 0.001271\n",
      "------------------------------------------------------------\n",
      "Epoch 10/10, Batch 0/406, Loss: 0.000802\n",
      "Epoch 10/10, Batch 10/406, Loss: 0.000140\n",
      "Epoch 10/10, Batch 20/406, Loss: 0.001822\n",
      "Epoch 10/10, Batch 30/406, Loss: 0.003118\n",
      "Epoch 10/10, Batch 40/406, Loss: 0.000356\n",
      "Epoch 10/10, Batch 50/406, Loss: 0.000217\n",
      "Epoch 10/10, Batch 60/406, Loss: 0.000880\n",
      "Epoch 10/10, Batch 70/406, Loss: 0.000346\n",
      "Epoch 10/10, Batch 80/406, Loss: 0.005639\n",
      "Epoch 10/10, Batch 90/406, Loss: 0.000434\n",
      "Epoch 10/10, Batch 100/406, Loss: 0.000706\n",
      "Epoch 10/10, Batch 110/406, Loss: 0.003619\n",
      "Epoch 10/10, Batch 120/406, Loss: 0.000337\n",
      "Epoch 10/10, Batch 130/406, Loss: 0.000090\n",
      "Epoch 10/10, Batch 140/406, Loss: 0.001868\n",
      "Epoch 10/10, Batch 150/406, Loss: 0.002643\n",
      "Epoch 10/10, Batch 160/406, Loss: 0.003967\n",
      "Epoch 10/10, Batch 170/406, Loss: 0.001925\n",
      "Epoch 10/10, Batch 180/406, Loss: 0.000878\n",
      "Epoch 10/10, Batch 190/406, Loss: 0.000713\n",
      "Epoch 10/10, Batch 200/406, Loss: 0.000331\n",
      "Epoch 10/10, Batch 210/406, Loss: 0.002949\n",
      "Epoch 10/10, Batch 220/406, Loss: 0.003965\n",
      "Epoch 10/10, Batch 230/406, Loss: 0.002058\n",
      "Epoch 10/10, Batch 240/406, Loss: 0.000398\n",
      "Epoch 10/10, Batch 250/406, Loss: 0.000497\n",
      "Epoch 10/10, Batch 260/406, Loss: 0.000580\n",
      "Epoch 10/10, Batch 270/406, Loss: 0.000281\n",
      "Epoch 10/10, Batch 280/406, Loss: 0.000766\n",
      "Epoch 10/10, Batch 290/406, Loss: 0.000277\n",
      "Epoch 10/10, Batch 300/406, Loss: 0.000691\n",
      "Epoch 10/10, Batch 310/406, Loss: 0.001822\n",
      "Epoch 10/10, Batch 320/406, Loss: 0.005174\n",
      "Epoch 10/10, Batch 330/406, Loss: 0.001907\n",
      "Epoch 10/10, Batch 340/406, Loss: 0.001797\n",
      "Epoch 10/10, Batch 350/406, Loss: 0.001738\n",
      "Epoch 10/10, Batch 360/406, Loss: 0.000323\n",
      "Epoch 10/10, Batch 370/406, Loss: 0.000141\n",
      "Epoch 10/10, Batch 380/406, Loss: 0.000487\n",
      "Epoch 10/10, Batch 390/406, Loss: 0.000306\n",
      "Epoch 10/10, Batch 400/406, Loss: 0.001998\n",
      "Epoch 10 completed - Average Loss: 0.001263\n",
      "Saved checkpoint: pong_model_epoch_10.pth\n",
      "------------------------------------------------------------\n",
      "Training completed! Final model saved as: pong_model_final.pth\n"
     ]
    }
   ],
   "source": [
    "trained_model = train_model(model, dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c90310a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No model path provided or file not found. Using randomly initialized model.\n",
      "Enabled CUDNN optimizations\n",
      "Warming up model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (200, 200) to (208, 208) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup complete!\n",
      "Loaded state_dict from: pong_model_final.pth\n",
      "Generating 1800 frames to: generated_20250809_011953\n",
      "Device: cuda\n",
      "Generated 100/1800 frames...\n",
      "Generated 200/1800 frames...\n",
      "Generated 300/1800 frames...\n",
      "Generated 400/1800 frames...\n",
      "Generated 500/1800 frames...\n",
      "Generated 600/1800 frames...\n",
      "Generated 700/1800 frames...\n",
      "Generated 800/1800 frames...\n",
      "Generated 900/1800 frames...\n",
      "Generated 1000/1800 frames...\n",
      "Generated 1100/1800 frames...\n",
      "Generated 1200/1800 frames...\n",
      "Generated 1300/1800 frames...\n",
      "Generated 1400/1800 frames...\n",
      "Generated 1500/1800 frames...\n",
      "Generated 1600/1800 frames...\n",
      "Generated 1700/1800 frames...\n",
      "Generated 1800/1800 frames...\n",
      "Saved video: generated_20250809_011953\\0gameplay.mp4\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "out_dir = generate_gameplay(num_frames=1800, fps=30, model_path=\"pong_model_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
