{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39496b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get the frames directory\n",
    "frames_dir = \"frames\"\n",
    "\n",
    "# Check if frames directory exists\n",
    "if not os.path.exists(frames_dir):\n",
    "    print(f\"Frames directory '{frames_dir}' not found!\")\n",
    "else:\n",
    "    # Get all PNG files in the frames directory\n",
    "    frame_files = [f for f in os.listdir(frames_dir) if f.endswith('.png')]\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(\"No PNG files found in frames directory!\")\n",
    "    else:\n",
    "        # Select a random frame\n",
    "        random_frame = random.choice(frame_files)\n",
    "        frame_path = os.path.join(frames_dir, random_frame)\n",
    "        \n",
    "        # Load and display the image\n",
    "        img = Image.open(frame_path)\n",
    "        \n",
    "        print(f\"Displayed frame: {random_frame}\")\n",
    "        print(f\"Image size: {img.size}\")\n",
    "\n",
    "        \n",
    "        # Convert image to tensor and extract black channel\n",
    "        import numpy as np\n",
    "        \n",
    "        # Convert PIL image to numpy array\n",
    "        img_array = np.array(img)\n",
    "        \n",
    "        # Check if image is RGB or RGBA\n",
    "        if len(img_array.shape) == 3:\n",
    "            black_channel = img_array[:, :, 0]\n",
    "        else:\n",
    "            # If it's already grayscale\n",
    "            black_channel = img_array\n",
    "        \n",
    "        # Convert to tensor (numpy array) and ensure it's 200x200\n",
    "        tensor_200x200 = black_channel.astype(np.float32)\n",
    "        \n",
    "        print(f\"Tensor shape: {tensor_200x200.shape}\")\n",
    "        print(f\"Tensor dtype: {tensor_200x200.dtype}\")\n",
    "        print(f\"Min value: {tensor_200x200.min()}, Max value: {tensor_200x200.max()}\")\n",
    "        print(\"\\nBlack channel tensor (200x200):\")\n",
    "        print(tensor_200x200)\n",
    "\n",
    "        # Display both images as subplots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "        \n",
    "        ax1.imshow(img)\n",
    "        ax1.set_title(f\"Random Frame: {random_frame}\")\n",
    "        ax1.axis('off')\n",
    "        \n",
    "        ax2.imshow(tensor_200x200, cmap='gray', vmin=0, vmax=255)\n",
    "        ax2.set_title(\"Tensor 200x200 (Black Channel)\")\n",
    "        ax2.axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc82cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RealTimePongPredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Lightweight U-Net for real-time next-frame prediction in Pong\n",
    "    Optimized for <16ms inference time on GPU for 60fps gameplay\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(RealTimePongPredictor, self).__init__()\n",
    "        \n",
    "        # Encoder (downsampling)\n",
    "        self.enc1 = self._conv_block(2, 32)       # Input: 2 frames (t-1, t)\n",
    "        self.enc2 = self._conv_block(32, 64)      # 100x100 -> 100x100  \n",
    "        self.enc3 = self._conv_block(64, 128)     # 50x50 -> 50x50\n",
    "        \n",
    "        # Bottleneck\n",
    "        self.bottleneck = self._conv_block(128, 256)  # 25x25 -> 25x25\n",
    "        \n",
    "        # Decoder (upsampling) with skip connections\n",
    "        self.dec3 = self._conv_block(256 + 128, 128)  # +128 from skip connection\n",
    "        self.dec2 = self._conv_block(128 + 64, 64)    # +64 from skip connection  \n",
    "        self.dec1 = self._conv_block(64 + 32, 32)     # +32 from skip connection\n",
    "        \n",
    "        # Final output layer\n",
    "        self.final = nn.Conv2d(32, 1, kernel_size=1)\n",
    "        \n",
    "    def _conv_block(self, in_channels, out_channels):\n",
    "        \"\"\"Lightweight convolution block\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Concatenated input frames [batch_size, 2, 200, 200] where x[:,0]=t-1, x[:,1]=t\n",
    "        Returns:\n",
    "            next_frame: Predicted next frame [batch_size, 1, 200, 200]\n",
    "        \"\"\"\n",
    "        # Encoder with skip connections\n",
    "        e1 = self.enc1(x)           # [B, 32, 200, 200]\n",
    "        e1_pool = F.max_pool2d(e1, 2)  # [B, 32, 100, 100]\n",
    "        \n",
    "        e2 = self.enc2(e1_pool)     # [B, 64, 100, 100]\n",
    "        e2_pool = F.max_pool2d(e2, 2)  # [B, 64, 50, 50]\n",
    "        \n",
    "        e3 = self.enc3(e2_pool)     # [B, 128, 50, 50]\n",
    "        e3_pool = F.max_pool2d(e3, 2)  # [B, 128, 25, 25]\n",
    "        \n",
    "        # Bottleneck\n",
    "        bottleneck = self.bottleneck(e3_pool)  # [B, 256, 25, 25]\n",
    "        \n",
    "        # Decoder with skip connections\n",
    "        d3 = F.interpolate(bottleneck, size=(50, 50), mode='bilinear', align_corners=False)\n",
    "        d3 = torch.cat([d3, e3], dim=1)  # Skip connection\n",
    "        d3 = self.dec3(d3)  # [B, 128, 50, 50]\n",
    "        \n",
    "        d2 = F.interpolate(d3, size=(100, 100), mode='bilinear', align_corners=False)\n",
    "        d2 = torch.cat([d2, e2], dim=1)  # Skip connection\n",
    "        d2 = self.dec2(d2)  # [B, 64, 100, 100]\n",
    "        \n",
    "        d1 = F.interpolate(d2, size=(200, 200), mode='bilinear', align_corners=False)\n",
    "        d1 = torch.cat([d1, e1], dim=1)  # Skip connection\n",
    "        d1 = self.dec1(d1)  # [B, 32, 200, 200]\n",
    "        \n",
    "        # Predict residual delta in [-1,1], then add to latest frame\n",
    "        residual = torch.tanh(self.final(d1))  # [B, 1, 200, 200]\n",
    "        latest = x[:, 1:2, :, :]               # most recent frame\n",
    "        output = torch.clamp(latest + residual, 0.0, 1.0)\n",
    "        \n",
    "        return output\n",
    "\n",
    "# Create model instance\n",
    "model = RealTimePongPredictor()\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"Model created successfully!\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Model size: ~{total_params * 4 / 1024 / 1024:.1f} MB (FP32)\")\n",
    "\n",
    "# Test inference speed\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    model = model.to(device)\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name()}\")\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "# Benchmark inference speed\n",
    "import time\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Warmup - FIXED: Use 2 channels input as expected by the model\n",
    "    for _ in range(10):\n",
    "        dummy_input = torch.randn(1, 2, 200, 200).to(device)  # Changed to 200x200\n",
    "        _ = model(dummy_input)\n",
    "    \n",
    "    # Actual timing - FIXED: Use 2 channels input as expected by the model\n",
    "    times = []\n",
    "    for _ in range(200):\n",
    "        dummy_input = torch.randn(1, 2, 200, 200).to(device)  # Changed to 200x200\n",
    "        start_time = time.time()\n",
    "        output = model(dummy_input)\n",
    "        torch.cuda.synchronize() if torch.cuda.is_available() else None\n",
    "        end_time = time.time()\n",
    "        times.append((end_time - start_time) * 1000)  # Convert to milliseconds\n",
    "    \n",
    "    avg_time = sum(times) / len(times)\n",
    "    print(f\"\\nInference Performance:\")\n",
    "    print(f\"Average inference time: {avg_time:.2f} ms\")\n",
    "    print(f\"Theoretical max FPS: {1000/avg_time:.1f}\")\n",
    "    print(f\"Real-time capable (60fps): {'✓ YES' if avg_time < 16.67 else '✗ NO'}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf84ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "class PongSequenceDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Dataset for loading consecutive Pong frames for next-frame prediction\n",
    "    \"\"\"\n",
    "    def __init__(self, frames_dir=\"frames\", sequence_length=3):\n",
    "        self.frames_dir = Path(frames_dir)\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        # Get all frame files and sort them by timestamp\n",
    "        self.frame_files = sorted([f for f in self.frames_dir.glob(\"*.png\")])\n",
    "        \n",
    "        # Group frames by recording session (same timestamp prefix)\n",
    "        self.sequences = self._group_sequences()\n",
    "        \n",
    "        print(f\"Found {len(self.frame_files)} total frames\")\n",
    "        print(f\"Created {len(self.sequences)} valid sequences\")\n",
    "    \n",
    "    def _group_sequences(self):\n",
    "        \"\"\"Group frames into sequences by timestamp\"\"\"\n",
    "        sequences = []\n",
    "        current_session = []\n",
    "        current_prefix = None\n",
    "        \n",
    "        for frame_file in self.frame_files:\n",
    "            # Extract timestamp prefix (everything before the frame number)\n",
    "            parts = frame_file.stem.split('_')\n",
    "            if len(parts) >= 3:\n",
    "                prefix = '_'.join(parts[:-1])  # All parts except the last (frame number)\n",
    "                \n",
    "                if current_prefix is None or prefix == current_prefix:\n",
    "                    current_session.append(frame_file)\n",
    "                    current_prefix = prefix\n",
    "                else:\n",
    "                    # New session started, process previous session\n",
    "                    if len(current_session) >= self.sequence_length:\n",
    "                        for i in range(len(current_session) - self.sequence_length + 1):\n",
    "                            sequences.append(current_session[i:i + self.sequence_length])\n",
    "                    \n",
    "                    # Start new session\n",
    "                    current_session = [frame_file]\n",
    "                    current_prefix = prefix\n",
    "        \n",
    "        # Process the last session\n",
    "        if len(current_session) >= self.sequence_length:\n",
    "            for i in range(len(current_session) - self.sequence_length + 1):\n",
    "                sequences.append(current_session[i:i + self.sequence_length])\n",
    "        \n",
    "        return sequences\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.sequences)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sequence = self.sequences[idx]\n",
    "        \n",
    "        # Load frames as tensors\n",
    "        frames = []\n",
    "        for frame_file in sequence:\n",
    "            img = Image.open(frame_file)\n",
    "            # Convert to grayscale tensor\n",
    "            img_array = np.array(img)\n",
    "            if len(img_array.shape) == 3:\n",
    "                img_array = img_array[:, :, 0]  # Use first channel\n",
    "            \n",
    "            # Normalize to [0, 1]\n",
    "            tensor = torch.from_numpy(img_array.astype(np.float32)) / 255.0\n",
    "            frames.append(tensor.unsqueeze(0))  # Add channel dimension\n",
    "        \n",
    "        # Return two input frames and target frame: (t-1, t) -> t+1\n",
    "        prev_frame = frames[0]\n",
    "        curr_frame = frames[1]\n",
    "        target_frame = frames[2]\n",
    "        \n",
    "        input_two = torch.cat([prev_frame, curr_frame], dim=0)  # [2, H, W]\n",
    "        return input_two, target_frame\n",
    "\n",
    "# Training configuration\n",
    "class TrainingConfig:\n",
    "    def __init__(self):\n",
    "        self.batch_size = 16\n",
    "        self.learning_rate = 1e-3\n",
    "        self.num_epochs = 10\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.save_every = 5  # Save model every N epochs\n",
    "        \n",
    "config = TrainingConfig()\n",
    "\n",
    "# Create dataset and dataloader\n",
    "try:\n",
    "    dataset = PongSequenceDataset(frames_dir=\"frames\")\n",
    "    dataloader = DataLoader(dataset, batch_size=config.batch_size, shuffle=True, num_workers=0)\n",
    "    \n",
    "    print(f\"Dataset created with {len(dataset)} training pairs\")\n",
    "    print(f\"Batch size: {config.batch_size}\")\n",
    "    print(f\"Training batches per epoch: {len(dataloader)}\")\n",
    "    \n",
    "    # Test loading a batch\n",
    "    sample_input, sample_target = next(iter(dataloader))\n",
    "    print(f\"Sample batch shapes - Input(two): {sample_input.shape}, Target: {sample_target.shape}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not create dataset: {e}\")\n",
    "    print(\"Make sure you have recorded some frames using F1 in the Pong game!\")\n",
    "    dataset = None\n",
    "    dataloader = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d24b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, config):\n",
    "    \"\"\"\n",
    "    Training loop for the Pong frame prediction model\n",
    "    \"\"\"\n",
    "    if dataloader is None:\n",
    "        print(\"No dataloader available. Please record some frames first!\")\n",
    "        return\n",
    "    \n",
    "    # Setup training\n",
    "    model = model.to(config.device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=config.learning_rate)\n",
    "    \n",
    "    # Weighted loss to emphasize white pixels (includes bottom row)\n",
    "    def weighted_l1_loss(predicted: torch.Tensor, target: torch.Tensor, white_weight: float = 4.0) -> torch.Tensor:\n",
    "        # target in [0,1]; weight white/intense pixels more\n",
    "        weights = 1.0 + white_weight * target\n",
    "        return torch.mean(weights * torch.abs(predicted - target))\n",
    "    \n",
    "    criterion = weighted_l1_loss\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    print(f\"Starting training on {config.device}\")\n",
    "    print(f\"Training for {config.num_epochs} epochs with {len(dataloader)} batches per epoch\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for epoch in range(config.num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        \n",
    "        for batch_idx, (input_frames, target_frames) in enumerate(dataloader):\n",
    "            # Move to device\n",
    "            input_frames = input_frames.to(config.device)       # [B, 2, H, W]\n",
    "            target_frames = target_frames.to(config.device)     # [B, 1, H, W]\n",
    "            \n",
    "            # Forward pass\n",
    "            optimizer.zero_grad()\n",
    "            predicted_frames = model(input_frames)\n",
    "            \n",
    "            # Calculate loss (both in [0,1])\n",
    "            loss = criterion(predicted_frames, target_frames)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # Print progress every 10 batches\n",
    "            if batch_idx % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{config.num_epochs}, \"\n",
    "                      f\"Batch {batch_idx}/{len(dataloader)}, \"\n",
    "                      f\"Loss: {loss.item():.6f}\")\n",
    "        \n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch+1} completed - Average Loss: {avg_loss:.6f}\")\n",
    "        \n",
    "        # Save model checkpoint\n",
    "        if (epoch + 1) % config.save_every == 0:\n",
    "            checkpoint_path = f\"pong_model_epoch_{epoch+1}.pth\"\n",
    "            torch.save({\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': avg_loss,\n",
    "            }, checkpoint_path)\n",
    "            print(f\"Saved checkpoint: {checkpoint_path}\")\n",
    "        \n",
    "        print(\"-\" * 60)\n",
    "    \n",
    "    # Save final model\n",
    "    final_path = \"pong_model_final.pth\"\n",
    "    torch.save(model.state_dict(), final_path)\n",
    "    print(f\"Training completed! Final model saved as: {final_path}\")\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Function to visualize predictions\n",
    "def visualize_predictions(model, dataloader, config, num_samples=4):\n",
    "    \"\"\"\n",
    "    Visualize model predictions vs ground truth\n",
    "    \"\"\"\n",
    "    if dataloader is None:\n",
    "        print(\"No dataloader available for visualization!\")\n",
    "        return\n",
    "    \n",
    "    model.eval()\n",
    "    model = model.to(config.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Get a batch of samples\n",
    "        input_frames, target_frames = next(iter(dataloader))\n",
    "        input_frames = input_frames.to(config.device)\n",
    "        target_frames = target_frames.to(config.device)\n",
    "        \n",
    "        # Make predictions\n",
    "        predicted_frames = model(input_frames)\n",
    "        \n",
    "        # Move to CPU for visualization\n",
    "        input_frames = input_frames.cpu()\n",
    "        target_frames = target_frames.cpu()\n",
    "        predicted_frames = predicted_frames.cpu()\n",
    "        \n",
    "        # Plot comparisons\n",
    "        fig, axes = plt.subplots(3, min(num_samples, len(input_frames)), figsize=(15, 9))\n",
    "        if min(num_samples, len(input_frames)) == 1:\n",
    "            axes = axes.reshape(-1, 1)\n",
    "        \n",
    "        for i in range(min(num_samples, len(input_frames))):\n",
    "            # Input frame\n",
    "            axes[0, i].imshow(input_frames[i, 1], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[0, i].set_title(f\"Input t (latest) {i+1}\")\n",
    "            axes[0, i].axis('off')\n",
    "            \n",
    "            # Ground truth next frame\n",
    "            axes[1, i].imshow(target_frames[i, 0], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[1, i].set_title(f\"Ground Truth {i+1}\")\n",
    "            axes[1, i].axis('off')\n",
    "            \n",
    "            # Predicted next frame\n",
    "            pred_frame = predicted_frames[i, 0]  # Already in [0,1]\n",
    "            axes[2, i].imshow(pred_frame, cmap='gray', vmin=0, vmax=1)\n",
    "            axes[2, i].set_title(f\"Predicted {i+1}\")\n",
    "            axes[2, i].axis('off')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Calculate and print metrics\n",
    "        mse = F.mse_loss(predicted_frames, target_frames).item()\n",
    "        mae = F.l1_loss(predicted_frames, target_frames).item()\n",
    "        \n",
    "        print(f\"Prediction Metrics:\")\n",
    "        print(f\"MSE: {mse:.4f}\")\n",
    "        print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Ready to train!\n",
    "print(\"Training setup complete!\")\n",
    "print(\"\\nTo start training, run:\")\n",
    "print(\"trained_model = train_model(model, dataloader, config)\")\n",
    "print(\"\\nTo visualize predictions:\")\n",
    "print(\"visualize_predictions(model, dataloader, config)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bfc0568",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RealTimeInference:\n",
    "    \"\"\"\n",
    "    Optimized inference class for real-time gameplay\n",
    "    \"\"\"\n",
    "    def __init__(self, model_path=None, device=None):\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        else:\n",
    "            self.device = device\n",
    "            \n",
    "        # Create model\n",
    "        self.model = RealTimePongPredictor()\n",
    "        \n",
    "        # Load trained weights if available\n",
    "        if model_path and Path(model_path).exists():\n",
    "            try:\n",
    "                state_dict = torch.load(model_path, map_location=self.device)\n",
    "                self.model.load_state_dict(state_dict)\n",
    "                print(f\"Loaded model from {model_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Could not load model from {model_path}: {e}\")\n",
    "                print(\"Using randomly initialized model\")\n",
    "        else:\n",
    "            print(\"No model path provided or file not found. Using randomly initialized model.\")\n",
    "        \n",
    "        # Optimize for inference\n",
    "        self.model = self.model.to(self.device)\n",
    "        self.model.eval()\n",
    "        \n",
    "        # Enable optimizations\n",
    "        if torch.cuda.is_available():\n",
    "            # Enable TensorRT optimizations if available\n",
    "            try:\n",
    "                import torch.backends.cudnn as cudnn\n",
    "                cudnn.benchmark = True\n",
    "                cudnn.deterministic = False\n",
    "                print(\"Enabled CUDNN optimizations\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Pre-allocate tensors for inference\n",
    "        self.input_tensor = torch.zeros(1, 2, 200, 200, device=self.device)\n",
    "        \n",
    "        # Warmup the model\n",
    "        self._warmup()\n",
    "        \n",
    "    def _warmup(self, warmup_iterations=50):\n",
    "        \"\"\"Warmup the model for consistent timing\"\"\"\n",
    "        print(\"Warming up model...\")\n",
    "        with torch.no_grad():\n",
    "            for _ in range(warmup_iterations):\n",
    "                dummy_input = torch.randn(1, 2, 200, 200, device=self.device)\n",
    "                _ = self.model(dummy_input)\n",
    "        print(\"Warmup complete!\")\n",
    "    \n",
    "    def predict_next_frame(self, prev_frame_np, current_frame_np, controls=None):\n",
    "        \"\"\"\n",
    "        Predict next frame from current frame\n",
    "        \n",
    "        Args:\n",
    "            prev_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "            current_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "            controls: dict with 'up' and 'down' boolean keys (optional)\n",
    "                     If provided, will overwrite the bottom row pixels\n",
    "        \n",
    "        Returns:\n",
    "            next_frame_np: numpy array of shape (100, 100) with values 0-255\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            # Convert numpy to tensor\n",
    "            prev_tensor = torch.from_numpy(prev_frame_np.astype(np.float32)) / 255.0\n",
    "            curr_tensor = torch.from_numpy(current_frame_np.astype(np.float32)) / 255.0\n",
    "            prev_tensor = prev_tensor.unsqueeze(0).unsqueeze(0)\n",
    "            curr_tensor = curr_tensor.unsqueeze(0).unsqueeze(0)\n",
    "            frame_tensor = torch.cat([prev_tensor, curr_tensor], dim=1).to(self.device)  # [1,2,100,100]\n",
    "            \n",
    "            # Apply control encoding if provided (overwrite on latest frame channel)\n",
    "            if controls is not None:\n",
    "                bottom_row = torch.zeros(1, 1, 1, 200, device=self.device)\n",
    "                if controls.get('up', False):\n",
    "                    bottom_row[0, 0, 0, :50] = 1.0\n",
    "                if controls.get('down', False):\n",
    "                    bottom_row[0, 0, 0, 50:] = 1.0\n",
    "                frame_tensor[:, 1:2, -1:, :] = bottom_row\n",
    "            \n",
    "            # Predict next frame\n",
    "            prediction = self.model(frame_tensor)\n",
    "            \n",
    "            # Convert back to numpy\n",
    "            prediction_np = prediction[0, 0].cpu().numpy()  # Remove batch and channel dims\n",
    "            prediction_np = np.clip(prediction_np * 255.0, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            return prediction_np\n",
    "    \n",
    "    def benchmark_inference(self, iterations=1000):\n",
    "        \"\"\"Benchmark inference speed\"\"\"\n",
    "        times = []\n",
    "        dummy_prev_frame = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
    "        dummy_curr_frame = np.random.randint(0, 256, (200, 200), dtype=np.uint8)\n",
    "        \n",
    "        for _ in range(iterations):\n",
    "            start_time = time.time()\n",
    "            _ = self.predict_next_frame(dummy_prev_frame, dummy_curr_frame)\n",
    "            if torch.cuda.is_available():\n",
    "                torch.cuda.synchronize()\n",
    "            end_time = time.time()\n",
    "            times.append((end_time - start_time) * 1000)  # Convert to ms\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        std_time = np.std(times)\n",
    "        min_time = np.min(times)\n",
    "        max_time = np.max(times)\n",
    "        \n",
    "        print(f\"\\nInference Benchmark Results ({iterations} iterations):\")\n",
    "        print(f\"Average time: {avg_time:.2f} ± {std_time:.2f} ms\")\n",
    "        print(f\"Min time: {min_time:.2f} ms\")\n",
    "        print(f\"Max time: {max_time:.2f} ms\")\n",
    "        print(f\"Theoretical max FPS: {1000/avg_time:.1f}\")\n",
    "        print(f\"Real-time capable (60fps): {'✓ YES' if avg_time < 16.67 else '✗ NO'}\")\n",
    "        print(f\"Real-time capable (30fps): {'✓ YES' if avg_time < 33.33 else '✗ NO'}\")\n",
    "        \n",
    "        return avg_time\n",
    "\n",
    "# Create inference engine\n",
    "inference_engine = RealTimeInference()\n",
    "\n",
    "# Benchmark performance\n",
    "inference_time = inference_engine.benchmark_inference()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"REAL-TIME GENERATIVE PONG MODEL READY!\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Model size: ~{sum(p.numel() for p in model.parameters()) * 4 / 1024 / 1024:.1f} MB\")\n",
    "print(f\"Inference time: {inference_time:.2f} ms\")\n",
    "print(f\"Device: {inference_engine.device}\")\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"1. Record training data: Play Pong and press F1 to record frames\")\n",
    "print(\"2. Train the model: trained_model = train_model(model, dataloader, config)\")\n",
    "print(\"3. Create generative gameplay integration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efc0853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "\n",
    "# ===== Continuous Generative Gameplay (ignores controls) =====\n",
    "\n",
    "def find_model_path():\n",
    "    \"\"\"Return best available model path (final first, else latest epoch).\"\"\"\n",
    "    final_path = Path(\"pong_model_final.pth\")\n",
    "    if final_path.exists():\n",
    "        return str(final_path)\n",
    "    # Fallback: latest epoch checkpoint\n",
    "    ckpts = sorted(glob.glob(\"pong_model_epoch_*.pth\"))\n",
    "    return ckpts[-1] if ckpts else None\n",
    "\n",
    "\n",
    "def robust_load_into_inference(inf_engine: RealTimeInference, model_path: str):\n",
    "    \"\"\"Load either a raw state_dict or a checkpoint dict into the inference model.\"\"\"\n",
    "    if not model_path:\n",
    "        print(\"No trained model found. Using random weights (results will be nonsense).\")\n",
    "        return\n",
    "    try:\n",
    "        state = torch.load(model_path, map_location=inf_engine.device)\n",
    "        # Check for checkpoint vs raw state_dict\n",
    "        if isinstance(state, dict) and \"model_state_dict\" in state:\n",
    "            inf_engine.model.load_state_dict(state[\"model_state_dict\"])\n",
    "            print(f\"Loaded checkpoint weights from: {model_path}\")\n",
    "        else:\n",
    "            inf_engine.model.load_state_dict(state)\n",
    "            print(f\"Loaded state_dict from: {model_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to load model from {model_path}: {e}\")\n",
    "        print(\"Continuing with randomly initialized model.\")\n",
    "\n",
    "\n",
    "def get_seed_frame(frames_dir=\"frames\"):\n",
    "    \"\"\"Pick a seed frame if available, else create a simple synthetic seed.\"\"\"\n",
    "    if os.path.isdir(frames_dir):\n",
    "        pngs = sorted([p for p in os.listdir(frames_dir) if p.endswith('.png')])\n",
    "        if pngs:\n",
    "            seed_path = os.path.join(frames_dir, pngs[0])\n",
    "            img = Image.open(seed_path).convert(\"L\")\n",
    "            return np.array(img, dtype=np.uint8)\n",
    "    # Create synthetic seed: paddles center, ball center, bottom row off\n",
    "    frame = np.zeros((200, 200), dtype=np.uint8)\n",
    "    # left paddle (player)\n",
    "    frame[82:118, 10:16] = 255\n",
    "    # right paddle (AI)\n",
    "    frame[82:118, 184:190] = 255\n",
    "    # ball\n",
    "    frame[97:103, 97:103] = 255\n",
    "    # bottom row zeros (controls off)\n",
    "    frame[-1, :] = 0\n",
    "    return frame\n",
    "\n",
    "\n",
    "def generate_gameplay(output_dir=None, num_frames=1200, save_video=True, fps=60, model_path=None):\n",
    "    \"\"\"\n",
    "    Generate continuous frames by feeding model outputs back as inputs.\n",
    "    Controls are ignored (bottom row forced to zero each step).\n",
    "    \"\"\"\n",
    "    # Prepare output directory\n",
    "    if output_dir is None:\n",
    "        ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_dir = Path(f\"generated_{ts}\")\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create inference engine and load trained weights\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    inf = RealTimeInference(model_path=None, device=device)\n",
    "    if model_path is None:\n",
    "        model_path = find_model_path()\n",
    "    robust_load_into_inference(inf, model_path)\n",
    "\n",
    "    # Get seed\n",
    "    # Bootstrap two frames: duplicate seed as both prev and current to start\n",
    "    prev = get_seed_frame()\n",
    "    current = prev.copy()\n",
    "\n",
    "    # Optional video writer\n",
    "    writer = None\n",
    "    video_path = output_dir / \"0gameplay.mp4\"\n",
    "    if save_video:\n",
    "        try:\n",
    "            import imageio\n",
    "            writer = imageio.get_writer(video_path, fps=fps)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not initialize video writer: {e}\")\n",
    "            print(\"Frames will still be saved as PNGs. To enable MP4, install: \\n\"\n",
    "                  \"pip install imageio[ffmpeg]\")\n",
    "\n",
    "    print(f\"Generating {num_frames} frames to: {output_dir}\")\n",
    "    print(f\"Device: {device}\")\n",
    "\n",
    "    for i in range(num_frames):\n",
    "        # Force controls off by overriding bottom row via controls param\n",
    "        # Predict using (prev, curr) -> next (do not override bottom row)\n",
    "        next_frame = inf.predict_next_frame(prev, current)\n",
    "\n",
    "        # Save PNG\n",
    "        out_path = output_dir / f\"frame_{i:05d}.png\"\n",
    "        Image.fromarray(next_frame).save(out_path)\n",
    "\n",
    "        # Append to video if available\n",
    "        if writer is not None:\n",
    "            try:\n",
    "                writer.append_data(next_frame)\n",
    "            except Exception as e:\n",
    "                print(f\"Video write error at frame {i}: {e}\")\n",
    "                writer = None  # Stop trying\n",
    "\n",
    "        # Feedback for next step (shift window)\n",
    "        prev = current\n",
    "        current = next_frame\n",
    "\n",
    "        # Light status\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Generated {i + 1}/{num_frames} frames...\")\n",
    "\n",
    "    if writer is not None:\n",
    "        writer.close()\n",
    "        print(f\"Saved video: {video_path}\")\n",
    "\n",
    "    print(\"Done.\")\n",
    "    return str(output_dir)\n",
    "\n",
    "# Example run (uncomment to execute):\n",
    "# out_dir = generate_gameplay(num_frames=1800, fps=60)\n",
    "# out_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369f9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = train_model(model, dataloader, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90310a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = generate_gameplay(num_frames=1800, fps=30, model_path=\"pong_model_final.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
